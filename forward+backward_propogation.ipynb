{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CROSS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def forward(x1, x2, wx11, wx12, wx21, wx22, wh1, wh2):\n",
    "    h1 = sigmoid(np.dot(x1,wx11) + np.dot(x2,wx21))\n",
    "    h2 = sigmoid(np.dot(x1,wx12) + np.dot(x2,wx22))\n",
    "    o = sigmoid(np.dot(h1,wh1) + np.dot(h2,wh2))\n",
    "    return h1, h2, o\n",
    "\n",
    "def binary_cross_entropy_loss(y, pred_y, n):\n",
    "    x = 0\n",
    "    for i in range(n):    \n",
    "        x += ( y[i] * np.log(pred_y[i]) + (1-y[i]) * np.log(1-pred_y[i]) )\n",
    "    return -1 * x/n\n",
    "\n",
    "def sigmoid_derivative(out):\n",
    "    return out * (1-out)\n",
    "\n",
    "def error_output(out, t):\n",
    "    return sigmoid_derivative(out) * (t - out)\n",
    "    \n",
    "def error_hidden(out, w_l, error_l):\n",
    "    return sigmoid_derivative(out) * w_l * error_l\n",
    "\n",
    "def delta_w(rate, error, neuron_value):\n",
    "    return rate * error * neuron_value\n",
    "\n",
    "def backward(target, predicted, wx11, wx12, wx21, wx22, wh1, wh2, rate, x1, x2, h1, h2):\n",
    "    error_out = error_output(predicted, target)\n",
    "    error_h1 = error_hidden(h1, wh1, error_out)\n",
    "    error_h2 = error_hidden(h2, wh2, error_out)\n",
    "    \n",
    "    wh1 = wh1 + delta_w(rate, error_out, h1)\n",
    "    wh2 = wh2 + delta_w(rate, error_out, h2)\n",
    "    \n",
    "    wx11 = wx11 + delta_w(rate, error_h1, x1)\n",
    "    wx12 = wx12 + delta_w(rate, error_h2, x1)\n",
    "    \n",
    "    wx21 = wx21 + delta_w(rate, error_h1, x2)\n",
    "    wx22 = wx22 + delta_w(rate, error_h2, x2)\n",
    "    \n",
    "    return wx11, wx12, wx21, wx22, wh1, wh2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Weights:  0.3 0.4 0.5 0.6 0.5 0.5 \n",
      "\n",
      "Epoch:  1\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.2950353205315705 0.3958770696395369 0.4900706410631411 0.5917541392790737 0.4536368774045292 0.4509121237612799\n",
      "Updated Weights:  0.28967465463682923 0.3923577461678634 0.48202964222102923 0.5864751540715635 0.4013569843273054 0.3961728511851299\n",
      "Updated Weights:  0.29081994783581355 0.3928713779649488 0.48393846421933645 0.5873312070667058 0.4275657046075914 0.42292932057574056\n",
      "Updated Weights:  0.2771055382117731 0.3835747176388955 0.48050986181332633 0.5850070419851925 0.37790860348365096 0.3698389184498505\n",
      "Updated Weights:  0.2688852385035132 0.37822304239288884 0.47502966200781976 0.5814392584878547 0.32712863724013114 0.31589760013160345\n",
      "Updated Weights:  0.27080726218669404 0.3790519682471353 0.4769516856910006 0.5822681843421011 0.35739088146876524 0.34703350826006596\n",
      "Updated Weights:  0.2727021172687642 0.3797879055470331 0.4784675697566567 0.5828569341820194 0.3861246924198661 0.37643799549522655\n",
      "Predicted:  [0.6918807400391506, 0.6944769731955958, 0.6849392508393007, 0.6764865692647728, 0.6594212762499467, 0.650330543679324, 0.6651276917767609] \n",
      "\n",
      "Epoch:  2\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.2687060484733091 0.37656427468568415 0.4704754321657465 0.5764096724593215 0.3403814923575659 0.3277088396966433\n",
      "Updated Weights:  0.2643161166033273 0.37380847778399756 0.4638905343607739 0.5722759771067916 0.28866074493216637 0.2731769417438724\n",
      "Updated Weights:  0.26552119328027995 0.374310629985069 0.46589899548902824 0.5731128974419106 0.32132781886692136 0.3066733558150948\n",
      "Updated Weights:  0.2544552123898919 0.3671402067066998 0.4631325002664312 0.5713202916223183 0.27303780264144095 0.2544883859016595\n",
      "Updated Weights:  0.24818692052055602 0.3632906456639853 0.4589536390202073 0.568753917593842 0.22392783438506464 0.20189015615453157\n",
      "Updated Weights:  0.24999456536405817 0.36399967312258813 0.46076128386370946 0.5694629450524449 0.26009463208988265 0.23929524016620837\n",
      "Updated Weights:  0.25193678996105756 0.36469140451569876 0.46231506354130897 0.5700163301669334 0.29450953731746043 0.2746836295092601\n",
      "Predicted:  [0.6477240388246044, 0.6457441065439956, 0.6328688484814737, 0.6309654884181342, 0.6131527601118755, 0.6007482882550376, 0.6187375926682315] \n",
      "\n",
      "Epoch:  3\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.24885603813685023 0.36231941227359654 0.4561535598928943 0.565272345682729 0.25012282438305755 0.22716400811930265\n",
      "Updated Weights:  0.24549986929325554 0.36035018268009394 0.45111930662750227 0.5623185012924751 0.20004981517525863 0.17406359307907388\n",
      "Updated Weights:  0.2465856047822593 0.36075680101796287 0.45292886577584185 0.5629961985222566 0.23790977031137783 0.2130288856349297\n",
      "Updated Weights:  0.2381384280301983 0.3556542875374688 0.4508170715878266 0.5617205701521331 0.1915958159827021 0.1625274525464475\n",
      "Updated Weights:  0.2336665897533987 0.35317180299300327 0.4478358460699602 0.5600655804558227 0.1446578606650202 0.11192476803727029\n",
      "Updated Weights:  0.23511029293319272 0.35364863509275823 0.4492795492497542 0.5605424125555776 0.18525656705234522 0.15408920609705304\n",
      "Updated Weights:  0.23685942701105542 0.3541980186350744 0.45067885651204437 0.5609819193894305 0.2240506097740157 0.19414220824306436\n",
      "Predicted:  [0.6106083330382733, 0.6047344389328558, 0.5893008099033256, 0.5938928903185351, 0.5759118791010536, 0.5609122828445238, 0.5811716424192763] \n",
      "\n",
      "Epoch:  4\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.23452951312356143 0.3525346408958956 0.4460190287370564 0.557655163911073 0.18119405075585537 0.1480805412367299\n",
      "Updated Weights:  0.2320703360704734 0.3512458876845496 0.44233026315742435 0.555722034094054 0.13306174099120846 0.09680348710632683\n",
      "Updated Weights:  0.2329317278307845 0.35151079690574066 0.4437659160912762 0.5561635494627057 0.17474670365887895 0.13983218219948712\n",
      "Updated Weights:  0.22667822876029975 0.34815348175487615 0.442202541323655 0.5553242206749897 0.13039857123316836 0.09112263625641087\n",
      "Updated Weights:  0.22364261931329496 0.34677363205078116 0.4401788016923185 0.5544043208722597 0.08554682386870566 0.042520231310901914\n",
      "Updated Weights:  0.22462509820832235 0.3469787823766945 0.4411612805873459 0.554609471198173 0.1292720611778871 0.08807942882304635\n",
      "Updated Weights:  0.22605653498044848 0.3473393153808829 0.44230643000504677 0.5548978976015237 0.17124611927345676 0.13155708773283797\n",
      "Predicted:  [0.5812034059695348, 0.5722805889749958, 0.5550076800846725, 0.5651512835091681, 0.5472330837372282, 0.5302938438242836, 0.552029087506576] \n",
      "\n",
      "Epoch:  5\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.22429823752612 0.34622878275347235 0.4387898350963898 0.5526768323467026 0.12980182408761776 0.08687107922263695\n",
      "Updated Weights:  0.22254064412569197 0.3454799301342337 0.43615344499574776 0.5515535534178447 0.08348370324440244 0.03734462966818587\n",
      "Updated Weights:  0.223149476798242 0.3455931580520151 0.4371681661166645 0.551742266614147 0.12787263825102513 0.08327195360151741\n",
      "Updated Weights:  0.2185862473366553 0.34361107681385095 0.4360273587512678 0.551246746304606 0.08522676283802694 0.036155377720936965\n",
      "Updated Weights:  0.21662252939492269 0.34307272574175096 0.4347182134567794 0.5508878455898727 0.04215458444821948 -0.010712701300363038\n",
      "Updated Weights:  0.21715472953702866 0.343016803502314 0.4352504135988854 0.5508319233504357 0.08803414072933294 0.03721469178219723\n",
      "Updated Weights:  0.21824285669204135 0.3431833433569981 0.43612091532289554 0.5509651552341831 0.13226148077253444 0.08314763483040782\n",
      "Predicted:  [0.558610744716304, 0.5473922321912005, 0.5288266439630653, 0.5433600581843196, 0.5255667301129702, 0.5072079008399448, 0.5298651770804096] \n",
      "\n",
      "Epoch:  6\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.2169038775772358 0.3424931273669331 0.43344295709328445 0.549584723254053 0.09201241748260931 0.03963054684793298\n",
      "Updated Weights:  0.21566736866033895 0.34215674043319616 0.43158819371793916 0.5490801428534476 0.04723509524409929 -0.008396905500767979\n",
      "Updated Weights:  0.21604152292502976 0.34212956073933143 0.4322117841590905 0.549034843363673 0.09351056172043748 0.03957491698211349\n",
      "Updated Weights:  0.212727088017365 0.34120036605026965 0.4313831754321743 0.5488025446914075 0.05225289980368564 -0.006235055910113342\n",
      "Updated Weights:  0.21153749737339136 0.3412913991895944 0.43059011500285854 0.5488632334509573 0.010621905536179525 -0.05169618661799475\n",
      "Updated Weights:  0.2116807494890303 0.34100806644252707 0.43073336711849747 0.54857990070389 0.05798094991482973 -0.002116213143237518\n",
      "Updated Weights:  0.21245563671980192 0.34099804900009073 0.43135327690311476 0.548571886749941 0.10379608168114038 0.045571513985089504\n",
      "Predicted:  [0.541474725489649, 0.5285523095362734, 0.5090819822914531, 0.5269565382909095, 0.5092890420361427, 0.48990091911479716, 0.5131280020329374] \n",
      "\n",
      "Epoch:  7\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.21141839987058708 0.34062585713364457 0.4292788032046851 0.5478275030170486 0.06451881475345281 0.0029970187828554026\n",
      "Updated Weights:  0.21055867165639963 0.3406008572156862 0.4279892108834039 0.5477900031401112 0.020994041966874773 -0.04381585766937158\n",
      "Updated Weights:  0.21073515389996783 0.3404531531812869 0.4282833479560176 0.5475438297494456 0.06858643208720341 0.00560411735124848\n",
      "Updated Weights:  0.2083221043995763 0.34032360473499096 0.4276800855809197 0.5475114426378717 0.028432402988887724 -0.0391771438341852\n",
      "Updated Weights:  0.20768187749979866 0.34088431697903354 0.4272532676477346 0.5478852508005667 -0.012056932091343335 -0.08353468714892967\n",
      "Updated Weights:  0.2075112723788793 0.34041318462636216 0.4270826625268152 0.5474141184478953 0.03632313662759228 -0.03278835310816187\n",
      "Updated Weights:  0.208025464565139 0.34025266740385257 0.42749401627582295 0.5472857046698877 0.0832601466445549 0.01616251130513715\n",
      "Predicted:  [0.5285233461683777, 0.5143391931747563, 0.4942348473086683, 0.5146067458905598, 0.49704955788174404, 0.47691916163699954, 0.5004999061471435] \n",
      "\n",
      "Epoch:  8\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.20720247739890466 0.3401226057439432 0.42584804194335424 0.547025581350069 0.04475910174068679 -0.02567370863208554\n",
      "Updated Weights:  0.20661043412069116 0.3403330466108992 0.424959977026034 0.547341242650503 0.002232887992356894 -0.0715309570256781\n",
      "Updated Weights:  0.206630060904957 0.34008611797845467 0.42499268833314374 0.5469296949297622 0.05074964594748864 -0.021073467971332742\n",
      "Updated Weights:  0.20485620087606723 0.34056552993123546 0.4245492233259213 0.5470495479179573 0.01146555851554526 -0.06506374221778866\n",
      "Updated Weights:  0.20460030600275025 0.3414790654673735 0.42437862674371 0.547658571608716 -0.0281259386221262 -0.10857181811738646\n",
      "Updated Weights:  0.20418748471214443 0.3408575212264565 0.4239658054531042 0.547037027367799 0.020963070387141028 -0.056988986236908526\n",
      "Updated Weights:  0.20449762881419437 0.34057348421274314 0.4242139207347442 0.5468097977568284 0.06869646678287564 -0.007118232162644664\n",
      "Predicted:  [0.5187257673242779, 0.5036046857548522, 0.48305607821034247, 0.505277814991448, 0.48781399601106346, 0.4671516350931322, 0.4909544100204702] \n",
      "\n",
      "Epoch:  9\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.20382444563985558 0.3406300170803801 0.4228675543860666 0.5469228634921023 0.03081181302289973 -0.048386813493566494\n",
      "Updated Weights:  0.20341913388039065 0.34101998915811016 0.4222595867468692 0.5475078216086974 -0.010923772570045884 -0.093505088820311\n",
      "Updated Weights:  0.20331969287879612 0.3406933067608188 0.4220938517442116 0.5469633509465451 0.038245355818388546 -0.04229366927337264\n",
      "Updated Weights:  0.20198969339460285 0.3416403501358926 0.42176135187316327 0.5472001117903136 -0.00035243831927300046 -0.0856856651912215\n",
      "Updated Weights:  0.201997508223504 0.34282184825059747 0.4217665617590974 0.5479877772001168 -0.03923717360375817 -0.12854792124552006\n",
      "Updated Weights:  0.2014044811817035 0.3420820621500343 0.42117353471729685 0.5472479910995537 0.01034557330203792 -0.07635452356451511\n",
      "Updated Weights:  0.20156304420082116 0.34169895062794914 0.42130038513259094 0.5469415018818856 0.058645944395921946 -0.02580493319187107\n",
      "Predicted:  [0.5112927860434067, 0.49547286229323095, 0.4746147565054212, 0.4981983911038719, 0.48081373063827204, 0.4597742444096014, 0.48371832454238384] \n",
      "\n",
      "Epoch:  10\n",
      "Target:  [0, 0, 1, 0, 0, 1, 1]\n",
      "Updated Weights:  0.2009920925508302 0.34190152883238867 0.420158481832609 0.5473466582907647 0.02125140980318848 -0.06664324838402805\n",
      "Updated Weights:  0.20071352347202784 0.3424300760721612 0.4197406282144055 0.5481394791504235 -0.01985782639314202 -0.11119682032384004\n",
      "Updated Weights:  0.20052747935610102 0.3420401906662246 0.41943055468786083 0.5474896701405292 0.029772769492204927 -0.05942933890406055\n",
      "Updated Weights:  0.199495760664998 0.343350490866096 0.41917262501508507 0.547817245190497 -0.008279880498355326 -0.10237535590310622\n",
      "Updated Weights:  0.19967857465568176 0.3447382025201774 0.4192945010088742 0.5487423862932179 -0.04660475237059942 -0.14475160949451915\n",
      "Updated Weights:  0.1989566677216476 0.3439066106282726 0.4185725940748401 0.5479107944013131 0.003320686257929993 -0.09210456403335172\n",
      "Updated Weights:  0.1990090865251373 0.34344518700269805 0.41861452911763186 0.5475416555008534 0.05202410739635867 -0.04104720910660004\n",
      "Predicted:  [0.5056330583477964, 0.4892895378355016, 0.4682192453475922, 0.49279869781759056, 0.47548232845752786, 0.45418077353751735, 0.4782158833835908] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = [1, 2, 3, 4, 3, 4, 5]\n",
    "x2 = [2, 3, 5, 1, 2, 4, 4]\n",
    "target = [0, 0, 1, 0, 0, 1, 1]\n",
    "\n",
    "wx11=0.3\n",
    "wx12=0.4\n",
    "wx21=0.5\n",
    "wx22=0.6 \n",
    "\n",
    "wh1=0.5\n",
    "wh2=0.5\n",
    "\n",
    "rate = 0.4\n",
    "\n",
    "print(\"Original Weights: \", wx11, wx12, wx21, wx22, wh1, wh2,\"\\n\")\n",
    "\n",
    "for i in range(10): #10 epochs\n",
    "    print(\"Epoch: \", i+1)\n",
    "    predicted = []\n",
    "    count = 0\n",
    "    print(\"Target: \", target)  \n",
    "    \n",
    "    for j in range(7):\n",
    "        h1, h2, o = forward(x1[count], x2[count], wx11, wx12, wx21, wx22, wh1, wh2)\n",
    "        predicted.append(o)\n",
    "        count+=1\n",
    "        \n",
    "        wx11, wx12, wx21, wx22, wh1, wh2 = backward(target[j], predicted[j], wx11, wx12, wx21, wx22, wh1, wh2, rate, x1[j], x2[j], h1, h2)\n",
    "        print(\"Updated Weights: \", wx11, wx12, wx21, wx22, wh1, wh2)\n",
    "    \n",
    "    print(\"Predicted: \", predicted, \"\\n\")\n",
    "    loss = binary_cross_entropy_loss(target ,predicted, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, pred_y, n):\n",
    "    x = 0\n",
    "    for i in range(n):\n",
    "        x +=  (y[i] - pred_y[i])**2\n",
    "    return x/n\n",
    "\n",
    "def forward(x1, x2, wx11, wx12, wx21, wx22, wh1, wh2):\n",
    "    h1 = np.dot(x1,wx11) + np.dot(x2,wx21)\n",
    "    h2 = np.dot(x1,wx12) + np.dot(x2,wx22)\n",
    "    o = np.dot(h1,wh1) + np.dot(h2,wh2)\n",
    "    return h1, h2, o\n",
    "\n",
    "def error_output(out, t):\n",
    "    return (t - out)\n",
    "    \n",
    "def error_hidden(out, w_l, error_l):\n",
    "    return w_l * error_l\n",
    "\n",
    "def delta_w(rate, error, neuron_value):\n",
    "    return rate * error * neuron_value\n",
    "\n",
    "def backward(target, predicted, wx11, wx12, wx21, wx22, wh1, wh2, rate, x1, x2, h1, h2):\n",
    "    error_out = error_output(predicted, target)\n",
    "    error_h1 = error_hidden(h1, wh1, error_out)\n",
    "    error_h2 = error_hidden(h2, wh2, error_out)\n",
    "    \n",
    "    wh1 = wh1 + delta_w(rate, error_out, h1)\n",
    "    wh2 = wh2 + delta_w(rate, error_out, h2)\n",
    "    \n",
    "    wx11 = wx11 + delta_w(rate, error_h1, x1)\n",
    "    wx12 = wx12 + delta_w(rate, error_h2, x1)\n",
    "    \n",
    "    wx21 = wx21 + delta_w(rate, error_h1, x2)\n",
    "    wx22 = wx22 + delta_w(rate, error_h2, x2)\n",
    "    \n",
    "    return wx11, wx12, wx21, wx22, wh1, wh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Weights:  0.3 0.4 0.5 0.6 0.5 0.5 \n",
      "\n",
      "Epoch:  1\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.300775 0.40077500000000005 0.50155 0.60155 0.502015 0.50248\n",
      "Updated Weights:  0.30341870399430293 0.4034211527704498 0.5055155559914545 0.6055192291556747 0.5075608196994121 0.5093423660149122\n",
      "Updated Weights:  0.309656477409313 0.4096808208664777 0.5159118450164714 0.6159520093157211 0.521644142672125 0.5267030493385984\n",
      "Updated Weights:  0.3157017306391008 0.41578470098260994 0.5174231583239183 0.6174779793447542 0.5267274092903278 0.5332353200864259\n",
      "Updated Weights:  0.3198613966728232 0.4199957612195038 0.5201962690130666 0.6202853528360168 0.5319446913387224 0.5397697441967845\n",
      "Updated Weights:  0.32830121849377547 0.42855973514299023 0.5286360908340189 0.6288493267595032 0.5452730262824758 0.5562748196102351\n",
      "Updated Weights:  0.3401900513071871 0.4406884450000422 0.5381471570847481 0.6385522946451447 0.5616519974603643 0.5765877676497246\n",
      "Predicted:  [1.4500000000000002, 2.3669073690000006, 3.903431225769657, 2.1027886947886993, 2.367603583716514, 4.03350594602601, 4.6393101289214655] \n",
      "\n",
      "Epoch:  2\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.34087188013746617 0.4413884054113778 0.5395108147453063 0.639952215467816 0.5633715673762351 0.578673117333386\n",
      "Updated Weights:  0.3432180761276622 0.44379832565965177 0.5430301087306003 0.643567095840227 0.5681613891562918 0.5845089881512525\n",
      "Updated Weights:  0.34869506174247167 0.44943289953413695 0.5521584180886161 0.6529580522977023 0.580194497036178 0.5991269413376124\n",
      "Updated Weights:  0.3542698552434572 0.4551896052524713 0.5535521164638625 0.6543972287272859 0.5848712826107699 0.6050137985923622\n",
      "Updated Weights:  0.35797709646461884 0.45902452100265334 0.5560236106113036 0.6569538392274072 0.589455991599982 0.6106643351928004\n",
      "Updated Weights:  0.36533113643315135 0.46664315579873966 0.5633776505798361 0.6645724740234936 0.6008590442907497 0.6245872566357954\n",
      "Updated Weights:  0.3756381653748046 0.47735721426536704 0.5716232737331587 0.6731437207967955 0.6148571333202946 0.6417119363570714\n",
      "Predicted:  [1.786029724167065, 2.9177188501694675, 4.786719572207763, 2.59787729396632, 2.8871469493178554, 4.881005506207856, 5.56923565032807] \n",
      "\n",
      "Epoch:  3\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.3761889841270366 0.47793209084875776 0.5727249112376227 0.674293473963577 0.6162178236936722 0.6433456454244614\n",
      "Updated Weights:  0.3781131107507611 0.4799409235001706 0.5756111011732095 0.6773067229406963 0.6200749469757245 0.6479961777335438\n",
      "Updated Weights:  0.38254891732403173 0.48457646912036356 0.5830041121286605 0.6850326323076845 0.6296427191105227 0.6595048851260136\n",
      "Updated Weights:  0.3874332689212144 0.4896924716425012 0.5842252000279562 0.686311632938219 0.6337409205247109 0.6645924162156512\n",
      "Updated Weights:  0.39054050476777885 0.49295097257267684 0.5862966905923325 0.6884839668916694 0.6375501483218897 0.6692367085095694\n",
      "Updated Weights:  0.39652386365017145 0.4992317073742037 0.592280049474725 0.6947647016931963 0.6467176899260969 0.6803243841341761\n",
      "Updated Weights:  0.40492082700130594 0.5080650190485922 0.5989976201556326 0.7018313510327071 0.6580182613500729 0.6940230373158782\n",
      "Predicted:  [2.1041516437199883, 3.4387609788767017, 5.615446006483966, 3.0606654182856943, 3.3656645032001378, 5.653769315973997, 6.403205917532877] \n",
      "\n",
      "Epoch:  4\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4053277908162962 0.5084942506969323 0.5998115477856132 0.7026898143293874 0.6590096150497777 0.6952053814122425\n",
      "Updated Weights:  0.40678732359036995 0.5100339475628225 0.6020008469467238 0.7049993596282226 0.6618999463436344 0.6986659716574704\n",
      "Updated Weights:  0.41009966042086865 0.5135302721099403 0.6075214083308884 0.7108265672067523 0.6689566008860596 0.7070983586077536\n",
      "Updated Weights:  0.4142235078619637 0.5178892480926645 0.6085523701911622 0.7119163112024334 0.6724209808375241 0.7113595551859012\n",
      "Updated Weights:  0.41670054974766546 0.5205097305942589 0.6102037314482966 0.7136632995368296 0.6754413934123337 0.71501569389124\n",
      "Updated Weights:  0.4212820228527864 0.5253596334922033 0.6147852045534176 0.718513202434774 0.6824068154189189 0.7233870057470998\n",
      "Updated Weights:  0.42778260564420567 0.5322505921034668 0.619985670786553 0.7240259693237848 0.6911050702295168 0.733867187478168\n",
      "Predicted:  [2.3815311232316194, 3.892631654574939, 6.331904568157061, 3.458850904665235, 3.7720778320467643, 6.304266976452504, 7.094807189922713] \n",
      "\n",
      "Epoch:  5\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4280549893254241 0.5325398295214245 0.6205304381489898 0.7246044441597003 0.6917623783279203 0.7346476796442476\n",
      "Updated Weights:  0.42907956033974726 0.5336279180643757 0.6220672946704746 0.726236576974127 0.6937749754694612 0.7370462459594822\n",
      "Updated Weights:  0.43135402666264444 0.5360442445738729 0.6258580718753033 0.730263787823289 0.6985806338575956 0.7427638344141786\n",
      "Updated Weights:  0.43476984774272903 0.5396761064379875 0.6267120271453245 0.7311717532893177 0.7014548660917891 0.7462775932011008\n",
      "Updated Weights:  0.4366770472077548 0.541705175299458 0.6279834934553417 0.7325244658636314 0.7037729568603109 0.7490702607372797\n",
      "Updated Weights:  0.4400127415529523 0.5452555666700558 0.6313191878005392 0.7360748572342292 0.7088191611942887 0.7551097661872659\n",
      "Updated Weights:  0.4448634741358438 0.5504230843488 0.6351997738668524 0.7402088713772246 0.715286639553916 0.7628709711308893\n",
      "Predicted:  [2.6058722574153355, 4.259448730935826, 6.9072026697810704, 3.777585251246422, 4.093693428130854, 6.815067305200682, 7.631320131154878] \n",
      "\n",
      "Epoch:  6\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4450235737138139 0.5505938345260994 0.6355199730227926 0.7405503717318233 0.7156705596087912 0.7633255256288546\n",
      "Updated Weights:  0.44568505798429786 0.5512993656139485 0.6365121994285186 0.741608668363597 0.7169629919719602 0.7648611522936816\n",
      "Updated Weights:  0.4471013361251633 0.5528102610756672 0.6388726629966276 0.7441268274664614 0.7199389863909649 0.768391785690945\n",
      "Updated Weights:  0.44992818385607397 0.5558273592143854 0.6395793749293552 0.744881102001141 0.7223216693187848 0.7712928561706106\n",
      "Updated Weights:  0.4513711600611666 0.5573681647666565 0.6405413590660837 0.7459083057026551 0.7240722756343314 0.7733952566963929\n",
      "Updated Weights:  0.453704741631845 0.5598607072635995 0.6428749406367621 0.7484008481995981 0.7275913537943067 0.7775955306957275\n",
      "Updated Weights:  0.45724775585174116 0.5636472173811476 0.6457093520126791 0.7514300562936366 0.7323050634589192 0.7832372556880223\n",
      "Predicted:  [2.7761742368486786, 4.537857005850892, 7.341538239898073, 4.018372464769003, 4.3341026736497765, 7.194285691772263, 8.026097767264613] \n",
      "\n",
      "Epoch:  7\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4573216287120307 0.5637262281367059 0.6458570977332582 0.751588077804753 0.7324814639776775 0.7834457190933591\n",
      "Updated Weights:  0.45770401703275715 0.56413522209442 0.6464306802143478 0.7522015687413242 0.7332259562180967 0.7843285538297355\n",
      "Updated Weights:  0.45846517575266527 0.5649494302016994 0.6476992780808614 0.7535585822534564 0.7348195249884891 0.7862156088869986\n",
      "Updated Weights:  0.4608382122519352 0.5674884459365002 0.6482925372056788 0.7541933361871566 0.7368230211565959 0.7886484526837728\n",
      "Updated Weights:  0.46192961850303094 0.5686566177042944 0.649020141373076 0.7549721173656861 0.7381458110659407 0.7902337921997926\n",
      "Updated Weights:  0.4635119779421768 0.5703506378849599 0.6506025008122218 0.7566661375463516 0.7405273484432486 0.7930712484197746\n",
      "Updated Weights:  0.4660839169731297 0.5731050680926022 0.6526600520369841 0.7588696817124654 0.7439448758648671 0.7971545363784253\n",
      "Predicted:  [2.8991228328524308, 4.738977476201299, 7.653968096531427, 4.1926464871401095, 4.506255812789999, 7.4640762653449055, 8.305376354739728] \n",
      "\n",
      "Epoch:  8\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4660954086390462 0.573117381684527 0.6526830353688171 0.7588943088963149 0.7439722386223422 0.797186833510202\n",
      "Updated Weights:  0.4662755047059272 0.5733103596020235 0.6529531794691387 0.7591837757725596 0.7443220640697997 0.7976011325802711\n",
      "Updated Weights:  0.46656431007079213 0.5736198378470347 0.6534345217439135 0.7596995728475784 0.7449252395736086 0.7983145366009511\n",
      "Updated Weights:  0.46860487656249006 0.5758066531228276 0.653944663366838 0.7602462766665267 0.7466507813816505 0.8004061072852834\n",
      "Updated Weights:  0.46944298118455646 0.5767050973149098 0.6545033997815489 0.7608452394612482 0.7476661457641748 0.8016213521078251\n",
      "Updated Weights:  0.4704891686720426 0.577826782753027 0.655549587269035 0.7619669248993653 0.7492388512384479 0.8034929473835318\n",
      "Updated Weights:  0.47237149782759935 0.5798454156611368 0.6570554505934804 0.7635818312258531 0.7517384327234352 0.806476079188549\n",
      "Predicted:  [2.9845530679901806, 4.878963180659457, 7.870662903060278, 4.3151774220773005, 4.6258381905949255, 7.650182272725206, 8.497535625002525] \n",
      "\n",
      "Epoch:  9\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.47233975950700485 0.579811366322645 0.6569919739522914 0.7635137325488696 0.7516630076172438 0.806387121478386\n",
      "Updated Weights:  0.47237920964061403 0.5798536885858941 0.6570511491527051 0.7635772159437434 0.7517395199608973 0.8064776603413102\n",
      "Updated Weights:  0.47234102448403825 0.5798127229655998 0.6569875072250789 0.7635089399099194 0.751659899461808 0.8063835621491499\n",
      "Updated Weights:  0.47414537732000994 0.5817484394622315 0.6574385954340718 0.7639928690340774 0.7531880229999413 0.8082335964695455\n",
      "Updated Weights:  0.47480687166340857 0.5824582780893514 0.6578795916630042 0.7644660947854905 0.7539893799094455 0.8091918449468458\n",
      "Updated Weights:  0.47548300370901087 0.5831839123648292 0.6585557237086065 0.7651917290609684 0.7550051045812796 0.8103996852106077\n",
      "Updated Weights:  0.47688989136724164 0.5846940231024106 0.6596812338351911 0.7663998176510335 0.7568728565964836 0.8126270943743569\n",
      "Predicted:  [3.0422198988543325, 4.973758098237228, 8.016931909507582, 4.399877245924781, 4.707246918786665, 7.775815129623085, 8.6273170473434] \n",
      "\n",
      "Epoch:  10\n",
      "Target:  [3, 5, 8, 5, 5, 8, 9]\n",
      "Updated Weights:  0.4768291391712429 0.5846287956602041 0.6595597294431936 0.7662693627666205 0.7567286761381301 0.8124571287207597\n",
      "Updated Weights:  0.4767736883134553 0.5845692611848712 0.6594765531565122 0.7661800610536212 0.7566212395938462 0.8123300638804393\n",
      "Updated Weights:  0.47651577237365866 0.5842923553026582 0.6590466932568512 0.765718551249933 0.7560840486750735 0.8116955062055857\n",
      "Updated Weights:  0.47815484520658397 0.586051985141643 0.6594564614650825 0.7661584587096792 0.7574742386168354 0.8133771510531999\n",
      "Updated Weights:  0.47869566375862205 0.5866327170407195 0.6598170071664412 0.7665456133090636 0.7581295205764641 0.8141602574542227\n",
      "Updated Weights:  0.47912210757223406 0.5870906778451163 0.6602434509800532 0.7670035741134603 0.7587699278842626 0.8149214130510299\n",
      "Updated Weights:  0.480207288534023 0.5882561657885604 0.6611115957494844 0.7679359644682157 0.7602105768186203 0.8166386262925669\n",
      "Predicted:  [3.0802673731383363, 5.036638533424286, 8.113626178374734, 4.458038813344384, 4.76200794497178, 7.85937633279081, 8.713963107416538] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x1 = [1, 2, 3, 4, 3, 4, 5]\n",
    "x2 = [2, 3, 5, 1, 2, 4, 4]\n",
    "target = [3, 5, 8, 5, 5, 8, 9]\n",
    "\n",
    "wx11=0.3\n",
    "wx12=0.4\n",
    "wx21=0.5\n",
    "wx22=0.6 \n",
    "\n",
    "wh1=0.5\n",
    "wh2=0.5\n",
    "\n",
    "rate = 0.001\n",
    "\n",
    "print(\"Original Weights: \", wx11, wx12, wx21, wx22, wh1, wh2,\"\\n\")\n",
    "\n",
    "for i in range(10): #100 epochs\n",
    "    print(\"Epoch: \", i+1)\n",
    "    predicted = []\n",
    "    count = 0\n",
    "    print(\"Target: \", target)  \n",
    "    \n",
    "    for j in range(7):\n",
    "        h1, h2, o = forward(x1[count], x2[count], wx11, wx12, wx21, wx22, wh1, wh2)\n",
    "        predicted.append(o)\n",
    "        count+=1\n",
    "        \n",
    "        wx11, wx12, wx21, wx22, wh1, wh2 = backward(target[j], predicted[j], wx11, wx12, wx21, wx22, wh1, wh2, rate, x1[j], x2[j], h1, h2)\n",
    "        print(\"Updated Weights: \", wx11, wx12, wx21, wx22, wh1, wh2)\n",
    "    \n",
    "    print(\"Predicted: \", predicted, \"\\n\")\n",
    "    loss = mean_squared_error(target ,predicted, 7)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
